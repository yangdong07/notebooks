{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Data Encoding and Processing\n",
    "\n",
    "主要问题是：\n",
    "\n",
    "1. 文件格式化处理（包括简单的如csv，tsv，以及复杂的如 xml、html等）\n",
    "2. 关系型数据库操作，以及其他\n",
    "\n",
    "涉及 Struct结构， 略去； 涉及 pandas操作，略去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "samples_path = './samples/'\n",
    "\n",
    "def open_samples(filename, *args, **kwargs):\n",
    "    return io.open(os.path.join(samples_path, filename), *args, **kwargs)\n",
    "\n",
    "open = open_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 CSV 文件处理\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as tuples:\n",
      "     ['AA', '39.48', '6/11/2007', '9:36am', '-0.18', '181800']\n",
      "     ['AIG', '71.38', '6/11/2007', '9:36am', '-0.15', '195500']\n",
      "     ['AXP', '62.58', '6/11/2007', '9:36am', '-0.46', '935000']\n",
      "     ['BA', '98.31', '6/11/2007', '9:36am', '+0.12', '104800']\n",
      "     ['C', '53.08', '6/11/2007', '9:36am', '-0.25', '360900']\n",
      "     ['CAT', '78.29', '6/11/2007', '9:36am', '-0.23', '225400']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# (a) Reading as tuples\n",
    "\n",
    "print('Reading as tuples:')\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # process row\n",
    "        print('    ', row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as namedtuples\n",
      "     Row(Symbol='AA', Price='39.48', Date='6/11/2007', Time='9:36am', Change='-0.18', Volume='181800')\n",
      "     Row(Symbol='AIG', Price='71.38', Date='6/11/2007', Time='9:36am', Change='-0.15', Volume='195500')\n",
      "     Row(Symbol='AXP', Price='62.58', Date='6/11/2007', Time='9:36am', Change='-0.46', Volume='935000')\n",
      "     Row(Symbol='BA', Price='98.31', Date='6/11/2007', Time='9:36am', Change='+0.12', Volume='104800')\n",
      "     Row(Symbol='C', Price='53.08', Date='6/11/2007', Time='9:36am', Change='-0.25', Volume='360900')\n",
      "     Row(Symbol='CAT', Price='78.29', Date='6/11/2007', Time='9:36am', Change='-0.23', Volume='225400')\n"
     ]
    }
   ],
   "source": [
    "# (b) Reading as namedtuples\n",
    "\n",
    "print('Reading as namedtuples')\n",
    "from collections import namedtuple\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    Row = namedtuple('Row', next(f_csv))   # headers 作为名称\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Process row\n",
    "        print('    ', row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts\n",
      "     OrderedDict([('Symbol', 'AA'), ('Price', '39.48'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.18'), ('Volume', '181800')])\n",
      "     OrderedDict([('Symbol', 'AIG'), ('Price', '71.38'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.15'), ('Volume', '195500')])\n",
      "     OrderedDict([('Symbol', 'AXP'), ('Price', '62.58'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.46'), ('Volume', '935000')])\n",
      "     OrderedDict([('Symbol', 'BA'), ('Price', '98.31'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '+0.12'), ('Volume', '104800')])\n",
      "     OrderedDict([('Symbol', 'C'), ('Price', '53.08'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.25'), ('Volume', '360900')])\n",
      "     OrderedDict([('Symbol', 'CAT'), ('Price', '78.29'), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', '-0.23'), ('Volume', '225400')])\n"
     ]
    }
   ],
   "source": [
    "# (c) Reading as dictionaries\n",
    "\n",
    "print('Reading as dicts')\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)   # 注意这里不用跳过头部\n",
    "    for row in f_csv:\n",
    "        # process row\n",
    "        print('    ', row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading into named tuples with type conversion\n",
      "('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800)\n",
      "('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500)\n",
      "('AXP', 62.58, '6/11/2007', '9:36am', -0.46, 935000)\n",
      "('BA', 98.31, '6/11/2007', '9:36am', 0.12, 104800)\n",
      "('C', 53.08, '6/11/2007', '9:36am', -0.25, 360900)\n",
      "('CAT', 78.29, '6/11/2007', '9:36am', -0.23, 225400)\n"
     ]
    }
   ],
   "source": [
    "# (d) Reading into tuples with type conversion\n",
    "\n",
    "print('Reading into named tuples with type conversion')\n",
    "\n",
    "col_types = [str, float, str, str, float, int]   # 类型转换\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts with type conversion\n",
      "OrderedDict([('Symbol', 'AA'), ('Price', 39.48), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.18), ('Volume', 181800)])\n",
      "OrderedDict([('Symbol', 'AIG'), ('Price', 71.38), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.15), ('Volume', 195500)])\n",
      "OrderedDict([('Symbol', 'AXP'), ('Price', 62.58), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.46), ('Volume', 935000)])\n",
      "OrderedDict([('Symbol', 'BA'), ('Price', 98.31), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', 0.12), ('Volume', 104800)])\n",
      "OrderedDict([('Symbol', 'C'), ('Price', 53.08), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.25), ('Volume', 360900)])\n",
      "OrderedDict([('Symbol', 'CAT'), ('Price', 78.29), ('Date', '6/11/2007'), ('Time', '9:36am'), ('Change', -0.23), ('Volume', 225400)])\n"
     ]
    }
   ],
   "source": [
    "# (e) Converting selected dict fields\n",
    "\n",
    "print('Reading as dicts with type conversion')\n",
    "\n",
    "field_types = [ ('Price', float),\n",
    "                ('Change', float),\n",
    "                ('Volume', int) ]   # 按照指定 field进行转换\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) \n",
    "                   for key, conversion in field_types)\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 JSON文件处理\n",
    "\n",
    "- json.loads  字符串\n",
    "- json.load   文件\n",
    "- json.dump   文件\n",
    "- json.dumps  字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('name', 'ACME'), ('shares', 50), ('price', 490.1)])\n"
     ]
    }
   ],
   "source": [
    "# Some advanced JSON examples involving ordered dicts and classes\n",
    "import json\n",
    "\n",
    "# Some JSON encoded text\n",
    "s = '{\"name\": \"ACME\", \"shares\": 50, \"price\": 490.1}'\n",
    "\n",
    "# (a) Turning JSON into an OrderedDict\n",
    "\n",
    "from collections import OrderedDict\n",
    "data = json.loads(s, object_pairs_hook=OrderedDict)   # 转成 OrderedDict\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 XML文件处理\n",
    "\n",
    "这也是一大类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vasudev Ram: Checking if web sites are online with Python\n",
      "Sat, 31 Mar 2018 01:46:42 +0000\n",
      "http://jugad2.blogspot.com/2018/03/checking-if-web-sites-are-online-with.html\n",
      "\n",
      "Continuum Analytics Blog: Improved Security &amp; Performance in Anaconda Distribution 5\n",
      "Fri, 30 Mar 2018 16:50:17 +0000\n",
      "https://www.anaconda.com/blog/developer-blog/improved-security-performance-in-anaconda-distribution-5/\n",
      "\n",
      "Stack Abuse: Single Page Apps with Vue.js and Flask: JWT Authentication\n",
      "Fri, 30 Mar 2018 14:00:00 +0000\n",
      "http://stackabuse.com/single-page-apps-with-vue-js-and-flask-jwt-authentication/\n",
      "\n",
      "Codementor: How to use Python to test your Ethereum Smart Contracts\n",
      "Fri, 30 Mar 2018 09:17:07 +0000\n",
      "https://www.codementor.io/mandarvaze/how-to-use-python-to-test-your-ethereum-smart-contracts-i2nlflu5w\n",
      "\n",
      "Codementor: Parallelizing Builds In Travis CI\n",
      "Fri, 30 Mar 2018 08:08:04 +0000\n",
      "https://www.codementor.io/parthshandilya/parallelizing-builds-in-travis-ci-hqb4yktmt\n",
      "\n",
      "Brandon Rhodes: A New Driver for the Original Twiddler\n",
      "Fri, 30 Mar 2018 04:00:00 +0000\n",
      "http://rhodesmill.org/brandon/2018/twiddler/\n",
      "\n",
      "Python Insider: Python 3.7.0b3 is now available for testing\n",
      "Thu, 29 Mar 2018 21:42:18 +0000\n",
      "http://feedproxy.google.com/~r/PythonInsider/~3/fX3AcI8XKGM/python-370b3-is-now-available-for.html\n",
      "\n",
      "Python Software Foundation: Python Developers Survey 2017 Results: Learn about the community\n",
      "Thu, 29 Mar 2018 19:01:54 +0000\n",
      "http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/KJeflni6tTQ/python-developers-survey-2017-results.html\n",
      "\n",
      "Python Engineering at Microsoft: Python in Visual Studio Code – March 2018 Release\n",
      "Thu, 29 Mar 2018 18:45:12 +0000\n",
      "https://blogs.msdn.microsoft.com/pythonengineering/2018/03/29/python-in-visual-studio-code-march-2018-release/\n",
      "\n",
      "Codementor: Python Code Help\n",
      "Thu, 29 Mar 2018 16:45:28 +0000\n",
      "https://www.codementor.io/michaelmarquez/python-code-help-i2um8p1br\n",
      "\n",
      "Test and Code: 39: Thorough software testing for critical features\n",
      "Thu, 29 Mar 2018 16:00:00 +0000\n",
      "http://testandcode.com/39\n",
      "\n",
      "PyCharm: Webinar: “Getting the Most Out of Django’s User Model” with Julia Looney\n",
      "Thu, 29 Mar 2018 15:00:50 +0000\n",
      "http://feedproxy.google.com/~r/Pycharm/~3/UGZV9kIQqio/\n",
      "\n",
      "Reuven Lerner: My new course, “Understanding and Mastering Git,” is now available\n",
      "Thu, 29 Mar 2018 13:21:11 +0000\n",
      "https://blog.lerner.co.il/my-new-course-understanding-and-mastering-git-is-now-available/\n",
      "\n",
      "Ned Batchelder: Is Python interpreted or compiled? Yes.\n",
      "Thu, 29 Mar 2018 12:25:00 +0000\n",
      "https://nedbatchelder.com//blog/201803/is_python_interpreted_or_compiled_yes.html\n",
      "\n",
      "Codementor: Data Science and Python\n",
      "Thu, 29 Mar 2018 11:04:45 +0000\n",
      "https://www.codementor.io/kunaldhawan93/data-science-and-python-i2ai6pntw\n",
      "\n",
      "Martin Fitzpatrick: Building a MicroPython heart rate monitor\n",
      "Wed, 28 Mar 2018 20:00:00 +0000\n",
      "https://martinfitzpatrick.name/article/wemos-heart-rate-sensor-display-micropython/\n",
      "\n",
      "Python Insider: Python 3.6.5 is now available\n",
      "Wed, 28 Mar 2018 17:59:10 +0000\n",
      "http://feedproxy.google.com/~r/PythonInsider/~3/IYL2xdpdWMY/python-365-is-now-available.html\n",
      "\n",
      "Continuum Analytics Blog: Anaconda Community Survey\n",
      "Wed, 28 Mar 2018 16:34:02 +0000\n",
      "https://www.anaconda.com/blog/developer-blog/anaconda-community-survey/\n",
      "\n",
      "PyCharm: PyCharm 2018.1 Out Now\n",
      "Wed, 28 Mar 2018 14:46:18 +0000\n",
      "http://feedproxy.google.com/~r/Pycharm/~3/CNm0bhTtz-Y/\n",
      "\n",
      "Codementor: How to use Python and Flask to build a web app — an in-depth tutorial\n",
      "Wed, 28 Mar 2018 14:10:33 +0000\n",
      "https://www.codementor.io/abhinavsuri/how-to-use-python-and-flask-to-build-a-web-app-an-in-depth-tutorial-hrncxg1m0\n",
      "\n",
      "Python Bytes: #71 We can migrate to Python 3, careful please\n",
      "Wed, 28 Mar 2018 08:00:00 +0000\n",
      "https://pythonbytes.fm/episodes/show/71/we-can-migrate-to-python-3-careful-please\n",
      "\n",
      "Python Sweetness: Crowdfunding Mitogen: day 23\n",
      "Wed, 28 Mar 2018 07:22:33 +0000\n",
      "http://pythonsweetness.tumblr.com/post/172336616242\n",
      "\n",
      "Full Stack Python: How to Send MMS Picture Messages with Python\n",
      "Wed, 28 Mar 2018 04:00:00 +0000\n",
      "https://www.fullstackpython.com/send-mms-picture-messages-python.html\n",
      "\n",
      "Montreal Python User Group: Montréal-Python 70 - Atomic Zucchini\n",
      "Wed, 28 Mar 2018 04:00:00 +0000\n",
      "http://montrealpython.org/en/2018/03/mp70/\n",
      "\n",
      "Davide Moro: Test automation framework thoughts and examples with Python, pytest and Jenkins\n",
      "Tue, 27 Mar 2018 23:48:51 +0000\n",
      "http://davidemoro.blogspot.com/2018/03/test-automation-python-pytest-jenkins.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "# Download the RSS feed and parse it\n",
    "u = urlopen('http://planet.python.org/rss20.xml')\n",
    "doc = parse(u)\n",
    "\n",
    "# Extract and output tags of interest\n",
    "for item in doc.iterfind('channel/item'):\n",
    "    title = item.findtext('title')\n",
    "    date = item.findtext('pubDate')\n",
    "    link = item.findtext('link')\n",
    "\n",
    "    print(title)\n",
    "    print(date)\n",
    "    print(link)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 处理大的XML文件（只是用少量内存，增量处理）\n",
    "\n",
    "\n",
    "用堆栈的方式递归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60617 13\n",
      "60626 8\n",
      "60651 7\n",
      "60647 6\n",
      "60623 6\n",
      "60613 4\n",
      "60636 4\n",
      "60625 4\n",
      "60628 4\n",
      "60609 4\n",
      "60622 3\n",
      "60657 3\n",
      "60619 3\n",
      "60629 3\n",
      "60641 3\n",
      "60618 2\n",
      "60644 2\n",
      "60654 2\n",
      "60649 2\n",
      "60638 2\n",
      "60656 2\n",
      "60660 1\n",
      "60643 1\n",
      "60634 1\n",
      "60632 1\n",
      "60639 1\n",
      "60630 1\n",
      "60612 1\n",
      "60616 1\n",
      "60614 1\n",
      "60652 1\n",
      "60707 1\n",
      "60631 1\n",
      "60637 1\n"
     ]
    }
   ],
   "source": [
    "# Example of incremental XML parsing\n",
    "#\n",
    "# The file 'potholes.xml' is a greatly condensed version of a larger\n",
    "# file available for download at\n",
    "#\n",
    "# https://data.cityofchicago.org/api/views/7as2-ds3y/rows.xml?accessType=DOWNLOAD\n",
    "\n",
    "from xml.etree.ElementTree import iterparse\n",
    "\n",
    "def parse_and_remove(filename, path):\n",
    "    path_parts = path.split('/')\n",
    "    doc = iterparse(filename, ('start', 'end'))\n",
    "    # Skip the root element\n",
    "    next(doc)\n",
    "\n",
    "    tag_stack = []\n",
    "    elem_stack = []\n",
    "    for event, elem in doc:\n",
    "        if event == 'start':\n",
    "            tag_stack.append(elem.tag)\n",
    "            elem_stack.append(elem)\n",
    "        elif event == 'end':\n",
    "            if tag_stack == path_parts:\n",
    "                yield elem\n",
    "                elem_stack[-2].remove(elem)\n",
    "            try:\n",
    "                tag_stack.pop()\n",
    "                elem_stack.pop()\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "# Find zip code with most potholes\n",
    "\n",
    "from collections import Counter\n",
    "potholes_by_zip = Counter()\n",
    "\n",
    "data = parse_and_remove(samples_path + 'potholes.xml', 'row/row')\n",
    "for pothole in data:\n",
    "    potholes_by_zip[pothole.findtext('zip')] += 1\n",
    "\n",
    "for zipcode, num in potholes_by_zip.most_common():\n",
    "    print(zipcode, num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 将字典转成xml文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<stock _id=\"1234\"><name>GOOG</name><shares>100</shares><price>490.1</price></stock>'\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import Element, tostring\n",
    "\n",
    "def dict_to_xml(tag, d):\n",
    "    elem = Element(tag)\n",
    "    for key, val in d.items():\n",
    "        child = Element(key)\n",
    "        child.text = str(val)\n",
    "        elem.append(child)\n",
    "    return elem\n",
    "\n",
    "s = {'name': 'GOOG', 'shares': 100, 'price': 490.1}\n",
    "e = dict_to_xml('stock', s)\n",
    "e.set('_id', '1234')   # attribute\n",
    "print(tostring(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Parsing, Modifying and Rewriting XML\n",
    "\n",
    "修改XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<stop>\n",
      "    <id>14791</id>\n",
      "    <nm>Clark &amp; Balmoral</nm>\n",
      "    <sri>\n",
      "        <rt>22</rt>\n",
      "        <d>North Bound</d>\n",
      "        <dd>North Bound</dd>\n",
      "    </sri>\n",
      "    <cr>22</cr>\n",
      "    <pre>\n",
      "       <pt>5 MIN</pt>\n",
      "       <fd>Howard</fd>\n",
      "       <v>1378</v>\n",
      "       <rn>22</rn>\n",
      "   </pre>\n",
      "   <pre>\n",
      "       <pt>15 MIN</pt>\n",
      "       <fd>Howard</fd>\n",
      "       <v>1867</v>\n",
      "       <rn>22</rn>\n",
      "   </pre>\n",
      "</stop>\n",
      "\n",
      "<?xml version='1.0' encoding='us-ascii'?>\n",
      "<stop>\n",
      "    <id>14791</id>\n",
      "    <nm>Clark &amp; Balmoral</nm>\n",
      "    <spam>This is a test</spam><pre>\n",
      "       <pt>5 MIN</pt>\n",
      "       <fd>Howard</fd>\n",
      "       <v>1378</v>\n",
      "       <rn>22</rn>\n",
      "   </pre>\n",
      "   <pre>\n",
      "       <pt>15 MIN</pt>\n",
      "       <fd>Howard</fd>\n",
      "       <v>1867</v>\n",
      "       <rn>22</rn>\n",
      "   </pre>\n",
      "</stop>\n"
     ]
    }
   ],
   "source": [
    "from xml.etree.ElementTree import parse, Element\n",
    "\n",
    "\n",
    "with open('pred.xml') as f:\n",
    "    print(f.read())\n",
    "doc = parse(samples_path + 'pred.xml')\n",
    "root = doc.getroot()\n",
    "\n",
    "# Remove a few elements 移除 sri 和cr\n",
    "root.remove(root.find('sri'))\n",
    "root.remove(root.find('cr'))\n",
    "\n",
    "# Insert a new element after <nm>...</nm>， 在 nm 元素后面插入新元素\n",
    "nm_index = root.getchildren().index(root.find('nm'))\n",
    "\n",
    "e = Element('spam')\n",
    "e.text = 'This is a test'\n",
    "root.insert(nm_index + 1, e)\n",
    "\n",
    "# Write back to a file\n",
    "doc.write(samples_path + 'newpred.xml', xml_declaration=True)\n",
    "\n",
    "with open('newpred.xml') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 关系型数据库操作（略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 十六进制编解码\n",
    "\n",
    "其实就是 ascii， 二进制编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656c6c6f'\n",
      "b'hello'\n"
     ]
    }
   ],
   "source": [
    "s = b'hello'\n",
    "\n",
    "import binascii\n",
    "\n",
    "h = binascii.b2a_hex(s)\n",
    "print(h)\n",
    "\n",
    "print(binascii.a2b_hex(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'68656C6C6F'\n",
      "b'hello'\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "h = base64.b16encode(s)\n",
    "print(h)\n",
    "print(base64.b16decode(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9 base64 编解码\n",
    "\n",
    "Base64是一种基于64个可打印字符来表示二进制数据的表示方法，参考 <https://zh.wikipedia.org/wiki/Base64>\n",
    "\n",
    "`ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/`  ， = 作为后缀\n",
    "\n",
    "每 6个bit 对应一个可打印字符（8bit）， 这样 编码会增加到 $4/3$ 倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'TWFuIGlzIGRpc3Rpbmd1aXNoZWQsIG5vdCBvbmx5IGJ5IGhpcyByZWFzb24sIGJ1dCBieSB0aGlzIHNpbmd1bGFyIHBhc3Npb24gZnJvbSBvdGhlciBhbmltYWxzLCB3aGljaCBpcyBhIGx1c3Qgb2YgdGhlIG1pbmQsIHRoYXQgYnkgYSBwZXJzZXZlcmFuY2Ugb2YgZGVsaWdodCBpbiB0aGUgY29udGludWVkIGFuZCBpbmRlZmF0aWdhYmxlIGdlbmVyYXRpb24gb2Yga25vd2xlZGdlLCBleGNlZWRzIHRoZSBzaG9ydCB2ZWhlbWVuY2Ugb2YgYW55IGNhcm5hbCBwbGVhc3VyZS4='\n",
      "b'Man is distinguished, not only by his reason, but by this singular passion from other animals, which is a lust of the mind, that by a perseverance of delight in the continued and indefatigable generation of knowledge, exceeds the short vehemence of any carnal pleasure.'\n"
     ]
    }
   ],
   "source": [
    "s = b'Man is distinguished, not only by his reason, but by this singular passion from other animals, which is a lust of the mind, that by a perseverance of delight in the continued and indefatigable generation of knowledge, exceeds the short vehemence of any carnal pleasure.'\n",
    "\n",
    "b = base64.b64encode(s)\n",
    "print(b)\n",
    "\n",
    "print(base64.b64decode(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
