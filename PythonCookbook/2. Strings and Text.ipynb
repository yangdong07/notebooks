{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Strings and Text\n",
    "\n",
    "字符串的基本操作，参考 <https://docs.python.org/3/library/string.html?highlight=string#module-string>\n",
    "\n",
    "\n",
    "主要是几大块：\n",
    "\n",
    "1. 正则表达式\n",
    "2. 编解码\n",
    "3. 格式化输出\n",
    "4. 格式化输入（html、xml文本）\n",
    "\n",
    "\n",
    "### 2.1 分割字符串\n",
    "\n",
    "string 自带 `split`方法。 但是如果想要更灵活，可以用 `re.split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdfjl', 'sdfj', 'sld', 'fsdkfj', 'sdfj', 'fsdfl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'asdfjl. sdfj sld; fsdkfj, sdfj, fsdfl'\n",
    "\n",
    "import re\n",
    "\n",
    "re.split(r'[;,\\.\\s]\\s*', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 startswith 和 endswith\n",
    "\n",
    "注意，这两个方法，可以用元组参数，比如 `endswith(('.c', '.h'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Matching Strings Using Shell Wildcard Patterns\n",
    "\n",
    "就是如何使用Unix shell通配符的形式，来匹配文件名字符串？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "\n",
    "assert fnmatch('foo.txt', '*.txt')\n",
    "assert fnmatch('foo.txt', '?oo.txt')\n",
    "assert fnmatch('Dat45.csv', 'Dat[0-9]*')\n",
    "\n",
    "\n",
    "assert fnmatchcase('foo.txt', '*.TXT') == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 字符串匹配问题\n",
    "\n",
    "这是一个非常大的问题。这里有简单的\n",
    "\n",
    "1. 一般用 str.find('xx')，可以找出子串的起始位置。\n",
    "2. 复杂一点的用 re.match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11/27/2012', '3/13/2013']\n",
      "2012-11-27\n",
      "2013-3-13\n",
      "('11', '27', '2012')\n",
      "('3', '13', '2013')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Some sample text\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "\n",
    "# (a) Find all matching dates\n",
    "datepat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "print(datepat.findall(text))\n",
    "\n",
    "# (b) Find all matching dates with capture groups\n",
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "for month, day, year in datepat.findall(text):\n",
    "    print('{}-{}-{}'.format(year, month, day))\n",
    "\n",
    "# (c) Iterative search\n",
    "for m in datepat.finditer(text):\n",
    "    print(m.groups())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 字符串替换\n",
    "\n",
    "- 一般用法是 `str.replace`方法\n",
    "- `re.sub(1, 2, text)`， 将1 替换为2\n",
    "- `pat.sub(func, text)`， pat为 re.compile 对象， func是替换方法，使用 match对象\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2012-11-27. PyCon starts 2013-3-13.\n",
      "Today is 27 Nov 2012. PyCon starts 13 Mar 2013.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Some sample text\n",
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "\n",
    "datepat = re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "\n",
    "# (a) Simple substitution\n",
    "print(datepat.sub(r'\\3-\\1-\\2', text))\n",
    "\n",
    "# (b) Replacement function\n",
    "from calendar import month_abbr\n",
    "\n",
    "def change_date(m):\n",
    "    mon_name = month_abbr[int(m.group(1))]\n",
    "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))\n",
    "\n",
    "print(datepat.sub(change_date, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 字符串匹配选项\n",
    "\n",
    "1. `re.IGNORECASE`，匹配时忽略大小写\n",
    "2. Shortest匹配（非贪婪匹配）： 例如`r'\\\"(.*?)\\\"'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no.\" Phone says \"yes.']\n",
      "['no.', 'yes.']\n"
     ]
    }
   ],
   "source": [
    "# Sample text\n",
    "text = 'Computer says \"no.\" Phone says \"yes.\"'\n",
    "\n",
    "# (a) Regex that finds quoted strings - longest match\n",
    "str_pat = re.compile(r'\\\"(.*)\\\"')\n",
    "print(str_pat.findall(text))\n",
    "\n",
    "# (b) Regex that finds quoted strings - shortest match\n",
    "str_pat = re.compile(r'\\\"(.*?)\\\"')\n",
    "print(str_pat.findall(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 字符串匹配之多行匹配\n",
    "\n",
    "`re.DOTALL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[' this is a\\n              multiline comment ']\n",
      "[' this is a\\n              multiline comment ']\n"
     ]
    }
   ],
   "source": [
    "text = '''/* this is a\n",
    "              multiline comment */\n",
    "'''\n",
    "comment = re.compile(r'/\\*(.*?)\\*/')\n",
    "print(comment.findall(text))   # no\n",
    "\n",
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "print(comment.findall(text))   # no\n",
    "\n",
    "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')\n",
    "print(comment.findall(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Unicode 字符处理\n",
    "\n",
    "这也是一个大问题。。\n",
    "\n",
    "参考这个 <https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386819196283586a37629844456ca7e5a7faa9b94ee8000>\n",
    "\n",
    "注意几点：\n",
    "\n",
    "1. 计算机内存里面都是 unicode编码。统一长度（4个字节，32位），方便处理。\n",
    "2. 传输或储存的时候，为了减少带宽和存储空间，用 utf-8编码， 这时候， 英文字符的ascii码和utf-8编码是一样的（1个字节，8位）。\n",
    "3. `bytes.decode()`， `str.encode()`，注意这两个用法和名称，编解码。\n",
    "4. 当然也可以转成其他码（`encode('gbk')`)，不过不建议使用\n",
    "\n",
    "python3 与python2 又不一样。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中\n",
      "b'\\\\u4e2d' 6\n",
      "b'\\xe4\\xb8\\xad' 3\n"
     ]
    }
   ],
   "source": [
    "s = '中'\n",
    "print(s)\n",
    "b1 = s.encode('ascii', 'backslashreplace')\n",
    "print(b1, len(b1))   # 注意这里是 unicode 编码，为什么是 6个bytes？，理论上，去掉 '\\u'，还有4个字节。\n",
    "b2 = s.encode('utf-8')\n",
    "print(b2, len(b2))   # utf-8编码，占 了三个bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "49\n",
      "50\n",
      "76\n",
      "78\n",
      "80\n",
      "82\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "print(sys.getsizeof(12))\n",
    "print(sys.getsizeof(''))  # 49 + 0\n",
    "print(sys.getsizeof('a'))  # 49 + 1\n",
    "print(sys.getsizeof('中'))   # 49 + 25 + 2\n",
    "print(sys.getsizeof('中文'))   # 49 + 25 + 4\n",
    "print(sys.getsizeof('中文字'))   # 49 + 25 + 6\n",
    "print(sys.getsizeof('中文字d'))   # 49 + 25 + 8\n",
    "print(sys.getsizeof('d中文字d2'))   # 49 + 25 + 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 strip，去掉首尾不想要的字符\n",
    "\n",
    "- strip\n",
    "- lstrip\n",
    "- rstrip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 清理字符串\n",
    "\n",
    "关于unicodedata的用法没有看懂。。。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pýtĥöñ\f",
      "is\tawesome\n",
      "\n",
      "whitespace remapped: pýtĥöñ is awesome\n",
      "\n",
      "accents removed: python is awesome\n",
      "\n",
      "accents removed via I/O: python is awesome\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A tricky string\n",
    "s = 'p\\xfdt\\u0125\\xf6\\xf1\\x0cis\\tawesome\\r\\n'\n",
    "print(s)\n",
    "\n",
    "# (a) Remapping whitespace\n",
    "remap = {\n",
    "    ord('\\t') : ' ',\n",
    "    ord('\\f') : ' ',\n",
    "    ord('\\r') : None      # Deleted\n",
    "}\n",
    "\n",
    "a = s.translate(remap)\n",
    "print('whitespace remapped:', a)\n",
    "\n",
    "# (b) Remove all combining characters/marks\n",
    "import unicodedata\n",
    "import sys\n",
    "cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode)\n",
    "                         if unicodedata.combining(chr(c)))\n",
    "\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "c = b.translate(cmb_chrs)\n",
    "print('accents removed:', c)\n",
    "\n",
    "# (c) Accent removal using I/O decoding\n",
    "d = b.encode('ascii','ignore').decode('ascii')\n",
    "print('accents removed via I/O:', d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 对齐字符串\n",
    "\n",
    "- ljust\n",
    "- rjust\n",
    "- center\n",
    "- format\n",
    "\n",
    "用 format 更灵活一些，可以用于数字之类的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello World         \"\n",
      "\"         Hello World\"\n",
      "\"    Hello World     \"\n",
      "\"Hello World=========\"\n",
      "\"---------Hello World\"\n",
      "\"****Hello World*****\"\n",
      "\"Hello World         \"\n",
      "\"         Hello World\"\n",
      "\"    Hello World     \"\n",
      "\"Hello World=========\"\n",
      "\"---------Hello World\"\n",
      "\"****Hello World*****\"\n",
      "\"Hello World         \"\n",
      "\"         Hello World\"\n",
      "\"1.23================\"\n",
      "\"----------------1.23\"\n",
      "\"********1.23********\"\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello World\"\n",
    "print('\"%s\"' % text.ljust(20))\n",
    "print('\"%s\"' % text.rjust(20))\n",
    "print('\"%s\"' % text.center(20))\n",
    "\n",
    "print('\"%s\"' % text.ljust(20, '='))\n",
    "print('\"%s\"' % text.rjust(20, '-'))\n",
    "print('\"%s\"' % text.center(20, '*'))\n",
    "\n",
    "print('\"%s\"' % format(text, '<20'))\n",
    "print('\"%s\"' % format(text, '>20'))\n",
    "print('\"%s\"' % format(text, '^20'))\n",
    "\n",
    "print('\"%s\"' % format(text, '=<20'))\n",
    "print('\"%s\"' % format(text, '->20'))\n",
    "print('\"%s\"' % format(text, '*^20'))\n",
    "\n",
    "print('\"%-20s\"' % text)\n",
    "print('\"%20s\"' % text)\n",
    "\n",
    "\n",
    "print('\"%s\"' % format(1.2345, '=<20.2f'))\n",
    "print('\"%s\"' % format(1.2345, '->20.2f'))\n",
    "print('\"%s\"' % format(1.2345, '*^20.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.12 拼接字符串\n",
    "\n",
    "`''.join` 很简单。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsChicagoNotChicago?\n",
      "IsChicagoNotChicago?\n",
      "IsChicagoNotChicago?\n"
     ]
    }
   ],
   "source": [
    "def sample():\n",
    "    yield \"Is\"\n",
    "    yield \"Chicago\"\n",
    "    yield \"Not\"\n",
    "    yield \"Chicago?\"\n",
    "\n",
    "# (a) Simple join operator\n",
    "text = ''.join(sample())\n",
    "print(text)\n",
    "\n",
    "# (b) Redirection of parts to I/O\n",
    "import sys\n",
    "for part in sample():\n",
    "    sys.stdout.write(part)\n",
    "sys.stdout.write('\\n')\n",
    "\n",
    "# (c) Combination of parts into buffers and larger I/O operations\n",
    "def combine(source, maxsize):\n",
    "    parts = []\n",
    "    size = 0\n",
    "    for part in source:\n",
    "        parts.append(part)\n",
    "        size += len(part)\n",
    "        if size > maxsize:\n",
    "            yield ''.join(parts)\n",
    "            parts = []\n",
    "            size = 0\n",
    "    yield ''.join(parts)\n",
    "\n",
    "for part in combine(sample(), 32768):\n",
    "    sys.stdout.write(part)\n",
    "sys.stdout.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.13 格式化文本（wrap）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,\n",
      "not around the eyes, don't look around the eyes, look into my eyes,\n",
      "you're under.\n",
      "\n",
      "Look into my eyes, look into my eyes,\n",
      "the eyes, the eyes, the eyes, not around\n",
      "the eyes, don't look around the eyes,\n",
      "look into my eyes, you're under.\n",
      "\n",
      "    Look into my eyes, look into my\n",
      "eyes, the eyes, the eyes, the eyes, not\n",
      "around the eyes, don't look around the\n",
      "eyes, look into my eyes, you're under.\n",
      "\n",
      "Look into my eyes, look into my eyes,\n",
      "    the eyes, the eyes, the eyes, not\n",
      "    around the eyes, don't look around\n",
      "    the eyes, look into my eyes, you're\n",
      "    under.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A long string\n",
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\"\n",
    "\n",
    "import textwrap\n",
    "\n",
    "print(textwrap.fill(s, 70))\n",
    "print()\n",
    "\n",
    "print(textwrap.fill(s, 40))\n",
    "print()\n",
    "\n",
    "print(textwrap.fill(s, 40, initial_indent='    '))\n",
    "print()\n",
    "\n",
    "print(textwrap.fill(s, 40, subsequent_indent='    '))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.14 Tokenizing Text\n",
    "\n",
    "类似于分割字符串，这里更多是提取操作符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='WS', value=' ')\n",
      "Token(type='NUM', value='42')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import namedtuple\n",
    "\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'\n",
    "NUM  = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "EQ    = r'(?P<EQ>=)'\n",
    "WS    = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))\n",
    "\n",
    "Token = namedtuple('Token', ['type','value'])\n",
    "\n",
    "def generate_tokens(pat, text):\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup, m.group())\n",
    "\n",
    "for tok in generate_tokens(master_pat, 'foo = 42'):\n",
    "    print(tok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.15 简单的表达式解析器\n",
    "\n",
    "表达式语法：\n",
    "\n",
    "```BNF\n",
    "expr ::= expr + term\n",
    "     |   expr - term\n",
    "     |   term\n",
    "term ::= term * factor\n",
    "     |   term / factor\n",
    "     |   factor\n",
    "factor ::= (expr)\n",
    "       |   NUM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n",
      "14\n",
      "37\n",
      "('+', 2, 3)\n",
      "('+', 2, ('*', 3, 4))\n",
      "('+', 2, ('*', ('+', 3, 4), 5))\n",
      "('+', ('+', 2, 3), 4)\n"
     ]
    }
   ],
   "source": [
    "# example.py\n",
    "#\n",
    "# An example of writing a simple recursive descent parser\n",
    "\n",
    "import re\n",
    "import collections\n",
    "\n",
    "# Token specification\n",
    "NUM    = r'(?P<NUM>\\d+)'\n",
    "PLUS   = r'(?P<PLUS>\\+)'\n",
    "MINUS  = r'(?P<MINUS>-)'\n",
    "TIMES  = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS     = r'(?P<WS>\\s+)'\n",
    "\n",
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES, \n",
    "                                  DIVIDE, LPAREN, RPAREN, WS]))\n",
    "\n",
    "# Tokenizer\n",
    "Token = collections.namedtuple('Token', ['type','value'])\n",
    "\n",
    "def generate_tokens(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgroup, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok\n",
    "\n",
    "# Parser \n",
    "class ExpressionEvaluator:\n",
    "    '''\n",
    "    Implementation of a recursive descent parser.   Each method\n",
    "    implements a single grammar rule.  Use the ._accept() method\n",
    "    to test and accept the current lookahead token.  Use the ._expect()\n",
    "    method to exactly match and discard the next token on on the input\n",
    "    (or raise a SyntaxError if it doesn't match).\n",
    "    '''\n",
    "\n",
    "    def parse(self,text):\n",
    "        self.tokens = generate_tokens(text)\n",
    "        self.tok = None             # Last symbol consumed\n",
    "        self.nexttok = None         # Next symbol tokenized\n",
    "        self._advance()             # Load first lookahead token\n",
    "        return self.expr()\n",
    "\n",
    "    def _advance(self):\n",
    "        'Advance one token ahead'\n",
    "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
    "\n",
    "    def _accept(self,toktype):\n",
    "        'Test and consume the next token if it matches toktype'\n",
    "        if self.nexttok and self.nexttok.type == toktype:\n",
    "            self._advance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def _expect(self,toktype):\n",
    "        'Consume next token if it matches toktype or raise SyntaxError'\n",
    "        if not self._accept(toktype):\n",
    "            raise SyntaxError('Expected ' + toktype)\n",
    "\n",
    "    # Grammar rules follow\n",
    "\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }*\"\n",
    "\n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval += right\n",
    "            elif op == 'MINUS':\n",
    "                exprval -= right\n",
    "        return exprval\n",
    "    \n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }*\"\n",
    "\n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval *= right\n",
    "            elif op == 'DIVIDE':\n",
    "                termval /= right\n",
    "        return termval\n",
    "\n",
    "    def factor(self):\n",
    "        \"factor ::= NUM | ( expr )\"\n",
    "\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    e = ExpressionEvaluator()\n",
    "    print(e.parse('2'))\n",
    "    print(e.parse('2 + 3'))\n",
    "    print(e.parse('2 + 3 * 4'))\n",
    "    print(e.parse('2 + (3 + 4) * 5'))\n",
    "\n",
    "# Example of building trees\n",
    "\n",
    "class ExpressionTreeBuilder(ExpressionEvaluator):\n",
    "    def expr(self):\n",
    "        \"expression ::= term { ('+'|'-') term }\"\n",
    "\n",
    "        exprval = self.term()\n",
    "        while self._accept('PLUS') or self._accept('MINUS'):\n",
    "            op = self.tok.type\n",
    "            right = self.term()\n",
    "            if op == 'PLUS':\n",
    "                exprval = ('+', exprval, right)\n",
    "            elif op == 'MINUS':\n",
    "                exprval = ('-', exprval, right)\n",
    "        return exprval\n",
    "    \n",
    "    def term(self):\n",
    "        \"term ::= factor { ('*'|'/') factor }\"\n",
    "\n",
    "        termval = self.factor()\n",
    "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
    "            op = self.tok.type\n",
    "            right = self.factor()\n",
    "            if op == 'TIMES':\n",
    "                termval = ('*', termval, right)\n",
    "            elif op == 'DIVIDE':\n",
    "                termval = ('/', termval, right)\n",
    "        return termval\n",
    "\n",
    "    def factor(self):\n",
    "        'factor ::= NUM | ( expr )'\n",
    "\n",
    "        if self._accept('NUM'):\n",
    "            return int(self.tok.value)\n",
    "        elif self._accept('LPAREN'):\n",
    "            exprval = self.expr()\n",
    "            self._expect('RPAREN')\n",
    "            return exprval\n",
    "        else:\n",
    "            raise SyntaxError('Expected NUMBER or LPAREN')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    e = ExpressionTreeBuilder()\n",
    "    print(e.parse('2 + 3'))\n",
    "    print(e.parse('2 + 3 * 4'))\n",
    "    print(e.parse('2 + (3 + 4) * 5'))\n",
    "    print(e.parse('2 + 3 + 4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-2aa16287ae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myacc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0myacc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ply'"
     ]
    }
   ],
   "source": [
    "# plyexample.py\n",
    "#\n",
    "# Example of parsing with PLY\n",
    "# need install PyParsing\n",
    "\n",
    "\n",
    "from ply.lex import lex\n",
    "from ply.yacc import yacc\n",
    "\n",
    "# Token list\n",
    "tokens = [ 'NUM', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN' ]\n",
    "\n",
    "# Ignored characters\n",
    "\n",
    "t_ignore = ' \\t\\n'\n",
    "\n",
    "# Token specifications (as regexs)\n",
    "t_PLUS   = r'\\+'\n",
    "t_MINUS  = r'-'\n",
    "t_TIMES  = r'\\*'\n",
    "t_DIVIDE = r'/'\n",
    "t_LPAREN = r'\\('\n",
    "t_RPAREN = r'\\)'\n",
    "\n",
    "# Token processing functions\n",
    "def t_NUM(t):\n",
    "    r'\\d+'\n",
    "    t.value = int(t.value)\n",
    "    return t\n",
    "\n",
    "# Error handler\n",
    "def t_error(t):\n",
    "    print('Bad character: {!r}'.format(t.value[0]))\n",
    "    t.skip(1)\n",
    "\n",
    "# Build the lexer\n",
    "lexer = lex()\n",
    "\n",
    "# Grammar rules and handler functions\n",
    "def p_expr(p):\n",
    "    '''\n",
    "    expr : expr PLUS term\n",
    "         | expr MINUS term\n",
    "    '''\n",
    "    if p[2] == '+':\n",
    "        p[0] = p[1] + p[3]\n",
    "    elif p[2] == '-':\n",
    "        p[0] = p[1] - p[3]\n",
    "\n",
    "def p_expr_term(p):\n",
    "    '''\n",
    "    expr : term\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_term(p):\n",
    "    '''\n",
    "    term : term TIMES factor\n",
    "         | term DIVIDE factor\n",
    "    '''\n",
    "    if p[2] == '*':\n",
    "        p[0] = p[1] * p[3]\n",
    "    elif p[2] == '/':\n",
    "        p[0] = p[1] / p[3]\n",
    "\n",
    "def p_term_factor(p):\n",
    "    '''\n",
    "    term : factor\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor(p):\n",
    "    '''\n",
    "    factor : NUM\n",
    "    '''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_factor_group(p):\n",
    "    '''\n",
    "    factor : LPAREN expr RPAREN\n",
    "    '''\n",
    "    p[0] = p[2]\n",
    "\n",
    "def p_error(p):\n",
    "    print('Syntax error')\n",
    "\n",
    "parser = yacc()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(parser.parse('2'))\n",
    "    print(parser.parse('2+3'))\n",
    "    print(parser.parse('2+(3+4)*5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
